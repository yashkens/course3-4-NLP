{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from fake_useragent import UserAgent\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "from collections import Counter\n",
    "from time import sleep\n",
    "from sklearn.metrics import accuracy_score\n",
    "session = requests.session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция ниже получает код страницы для поиска тегов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(link_part):\n",
    "    ua = UserAgent(verify_ssl=False)\n",
    "    headers = {'User-Agent': ua.random}\n",
    "    link = 'https://irecommend.ru' + link_part\n",
    "    response = session.get(link, headers=headers)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция для выбора слов и добавления их в словарь\n",
    "Берутся тексты длиной более 200 слов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала я составляла обычные каунтеры, но тогда результат получался плохой - получалось очень много названий конкретных фильмов и имен. Я связываю это с тем, что некоторые отзывы были значительно больше остальных, поэтому слова из этих отзывов значительно перевешивали. Чтобы попробовать от этого избавиться, я считаю частотность по тексту (кол-во этот слова/кол-во всех слов в тексте) и ее прибавляю к текущему значению в словаре. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_lemmas(text, freq, count):\n",
    "    counter = Counter()\n",
    "    text = text.text\n",
    "    words = nltk.word_tokenize(text.lower())\n",
    "    lemmas = [morph.parse(word)[0].normal_form for word in words]\n",
    "    if len(lemmas) > 200:\n",
    "        count += 1\n",
    "        for lemma in lemmas:\n",
    "            if lemma.isalpha():\n",
    "                counter[lemma] += 1\n",
    "    for word in dict(counter).keys():\n",
    "        freq[word] += counter[word]/len(lemmas)\n",
    "    return freq, count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция собирает не менее 30 отзывов и собирает словарь\n",
    "По каждому фильму не больше 2 плохих и 2 хороших отзывов, чтобы не было перевеса слов, относящихся к определенному жанру или фильму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_words(link):\n",
    "    b_count_all = 0\n",
    "    g_count_all = 0\n",
    "    b_freq = Counter()\n",
    "    g_freq = Counter()\n",
    "    \n",
    "    soup = get_soup(link)\n",
    "    all_films = soup.find_all('a', {'class': 'read-all-reviews-link-bottom read-all-reviews-link'})\n",
    "    \n",
    "    for film in all_films:\n",
    "        b_count = 0\n",
    "        g_count = 0\n",
    "        if b_count_all > 30 and g_count_all > 30:\n",
    "            break\n",
    "        sleep(10)\n",
    "        soup = get_soup(film.get('href'))\n",
    "        all_reviews = soup.find_all('a', {'class': 'more'})\n",
    "        \n",
    "        for review in all_reviews:\n",
    "            sleep(10)\n",
    "            soup = get_soup(review.get('href'))\n",
    "            recommend = soup.find('span', {'class': 'verdict'})\n",
    "            \n",
    "            if recommend.text == 'не рекомендует' and b_count <= 2 and b_count_all <= 30:\n",
    "                text = soup.find('div', {'class': 'description hasinlineimage'})\n",
    "                b_freq, b_count = get_text_lemmas(text, b_freq, b_count)\n",
    "                b_count_all += b_count\n",
    "                \n",
    "            elif g_count <= 2 and g_count_all <= 30:\n",
    "                text = soup.find('div', {'class': 'description hasinlineimage'})\n",
    "                g_freq, g_count = get_text_lemmas(text, g_freq, g_count)\n",
    "                g_count_all += g_count\n",
    "                \n",
    "            elif g_count > 2 and b_count > 2:\n",
    "                break\n",
    "                \n",
    "    return b_freq, g_freq, b_count_all, g_count_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Собираем словари и смотрим содержимое\n",
    "Было собрано по 33 отзыва каждой категории. Очень много частотных слов, списки ни о чем не говорят."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = '/category/filmy'\n",
    "bad_freq, good_freq, b_count_all, g_count_all = find_words(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 33)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_count_all, g_count_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('и', 0.5378129689888559),\n",
       " ('в', 0.39058127929404646),\n",
       " ('не', 0.3888307507659),\n",
       " ('фильм', 0.30171875052126335),\n",
       " ('на', 0.19723604679076498),\n",
       " ('что', 0.17145891701787222),\n",
       " ('но', 0.1691846920627757),\n",
       " ('это', 0.16692882453572386),\n",
       " ('он', 0.16436441215696262),\n",
       " ('я', 0.16368935203559262),\n",
       " ('весь', 0.14629756267375094),\n",
       " ('с', 0.1382083033589317),\n",
       " ('быть', 0.11713984116980514),\n",
       " ('как', 0.08697329060788114),\n",
       " ('о', 0.08190591509647052)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_freq.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('и', 0.5494357201808143),\n",
       " ('в', 0.4011236700064026),\n",
       " ('фильм', 0.24964370411324904),\n",
       " ('не', 0.24165901205663803),\n",
       " ('на', 0.18510632686128478),\n",
       " ('он', 0.1674328990918463),\n",
       " ('что', 0.1607037606587872),\n",
       " ('я', 0.1459989414092995),\n",
       " ('с', 0.13090616239170158),\n",
       " ('который', 0.12622684384467367),\n",
       " ('но', 0.12062355645646797),\n",
       " ('это', 0.11292778782128195),\n",
       " ('весь', 0.1110795363449208),\n",
       " ('очень', 0.08910775754872191),\n",
       " ('этот', 0.08854895542621703)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_freq.most_common(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция удаляет стоп-слова\n",
    "Я не стала отбирать слова по частотности, потому что не ясно, где устанавливать нижнюю границу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_words(freq):\n",
    "    stopWords = set(stopwords.words('russian'))\n",
    "    selected_freq = Counter()\n",
    "    for word in dict(freq).keys():\n",
    "        if word not in stopWords:\n",
    "            selected_freq[word] = freq[word]\n",
    "    return selected_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция удаляет общие для двух словарей слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_common_words(good_freq, bad_freq):\n",
    "    good = dict(good_freq)\n",
    "    bad = dict(bad_freq)\n",
    "    keys = list(bad.keys())\n",
    "    for b_key in keys:\n",
    "        if b_key in good.keys():\n",
    "            del bad[b_key]\n",
    "            del good[b_key]\n",
    "    return Counter(good), Counter(bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bad_freq = select_words(bad_freq)\n",
    "new_good_freq = select_words(good_freq)\n",
    "pos_freq, neg_freq = delete_common_words(new_good_freq, new_bad_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('дельфин', 0.025),\n",
       " ('заповедник', 0.016734105610770003),\n",
       " ('дочь', 0.015946329205949163),\n",
       " ('природа', 0.015425416693840484),\n",
       " ('произведение', 0.014968827018486218),\n",
       " ('соната', 0.014877680121966736),\n",
       " ('композитор', 0.013701631434605833),\n",
       " ('рейберн', 0.013433775577766705),\n",
       " ('мистический', 0.013047284540497209),\n",
       " ('бесшумный', 0.012942671472308018),\n",
       " ('пейзаж', 0.012870093606007965),\n",
       " ('квеста', 0.012687427912341407),\n",
       " ('загадка', 0.012687365806859625),\n",
       " ('николай', 0.011928777681208647),\n",
       " ('роза', 0.011834319526627219)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_freq.most_common(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, в списках очень много каких-то случайных существительных. Я решила, что будет намного показательнее, если в списках останутся только прилагательные. Это должно увеличить точность оценки, даже несмотря на то, что некоторые \"полезные\" существительные и глаголы уберутся."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция для отбора прилагательных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj(freq):\n",
    "    result = Counter()\n",
    "    for word in dict(freq).keys():\n",
    "        if morph.parse(word)[0].tag.POS == 'ADJF':\n",
    "            result[word] = freq[word]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_neg = get_adj(neg_freq)\n",
    "adj_pos = get_adj(pos_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('неприятный', 0.017958297260874202),\n",
       " ('обычный', 0.00948041743980214),\n",
       " ('откровенный', 0.00875171135994731),\n",
       " ('русский', 0.008327136337893296),\n",
       " ('худой', 0.007745603652079546),\n",
       " ('крутой', 0.007576847671636959),\n",
       " ('слабый', 0.007369154145425918),\n",
       " ('отвратительный', 0.006828120507815455),\n",
       " ('эмоциональный', 0.006717694823274509),\n",
       " ('голливудский', 0.005462976009017432),\n",
       " ('малопонятный', 0.0047169811320754715),\n",
       " ('бредовый', 0.0047169811320754715),\n",
       " ('неубедительный', 0.0045662100456621),\n",
       " ('типичный', 0.004538405400474366),\n",
       " ('грязный', 0.004527713582857983)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_neg.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('мистический', 0.013047284540497209),\n",
       " ('бесшумный', 0.012942671472308018),\n",
       " ('детективный', 0.011606503497547806),\n",
       " ('местный', 0.010857005095975591),\n",
       " ('интригующий', 0.009847310183448105),\n",
       " ('неизвестный', 0.006014741419145664),\n",
       " ('штормовой', 0.005494505494505495),\n",
       " ('удивительный', 0.005402930402930403),\n",
       " ('одинокий', 0.005402930402930403),\n",
       " ('грустный', 0.005402930402930403),\n",
       " ('истинный', 0.005372811820186004),\n",
       " ('душевный', 0.00510752688172043),\n",
       " ('морской', 0.00510752688172043),\n",
       " ('невероятный', 0.005106199107495399),\n",
       " ('документальный', 0.004943170683911424)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_pos.most_common(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получились относительно нормальные списки с наличием подходящих оценочных слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция собирает тестовую выборку\n",
    "Скачивается не менее 10 отзывов с их оценкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_link = 'https://irecommend.ru/category/filmy?page=499'\n",
    "\n",
    "def get_test_texts(n):\n",
    "    text_dict = {}\n",
    "    b_count_all = 0\n",
    "    g_count_all = 0\n",
    "\n",
    "    soup = get_soup('/category/filmy?page=499')\n",
    "    all_books = soup.find_all('a', {'class': 'read-all-reviews-link-bottom read-all-reviews-link'})\n",
    "\n",
    "    for book in all_books:\n",
    "        b_count = 0\n",
    "        g_count = 0\n",
    "        if b_count_all > n and g_count_all > n:\n",
    "            break\n",
    "        sleep(10)\n",
    "        soup = get_soup(book.get('href'))\n",
    "        all_reviews = soup.find_all('a', {'class': 'more'})\n",
    "        \n",
    "        for review in all_reviews:\n",
    "            sleep(10)\n",
    "            soup = get_soup(review.get('href'))\n",
    "            recommend = soup.find('span', {'class': 'verdict'})\n",
    "            \n",
    "            if recommend.text == 'не рекомендует' and b_count <= 2 and b_count_all <= n:\n",
    "                text = soup.find('div', {'class': 'description hasinlineimage'})\n",
    "                text_dict[text.text] = recommend.text\n",
    "                b_count += 1\n",
    "                b_count_all += b_count\n",
    "                \n",
    "            elif g_count <= 2 and g_count_all <= n:\n",
    "                text = soup.find('div', {'class': 'description hasinlineimage'})\n",
    "                text_dict[text.text] = recommend.text\n",
    "                g_count += 1\n",
    "                g_count_all += g_count\n",
    "                \n",
    "            elif g_count > 2 and b_count > 2:\n",
    "                break\n",
    "                \n",
    "    return text_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = get_test_texts(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция, предсказывающая оценку\n",
    "Итоговые положительные и отрицательные очки делятся на суммы всех значений в соответствующих словарях, чтобы получить процентные соотношения. Нельзя сравнивать очки, потому что суммы значений в разных оценках могут отличаться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_verdict(text, adj_pos, adj_neg):\n",
    "    pos_score = 0\n",
    "    neg_score = 0\n",
    "    words = nltk.word_tokenize(text.lower())\n",
    "    lemmas = [morph.parse(word)[0].normal_form for word in words]\n",
    "    for lemma in lemmas:\n",
    "        if lemma in adj_pos.keys():\n",
    "            pos_score += adj_pos[lemma]\n",
    "        elif lemma in adj_neg.keys():\n",
    "            neg_score += adj_neg[lemma]\n",
    "    n_score = neg_score/sum(adj_neg.values())\n",
    "    p_score = pos_score/sum(adj_pos.values())\n",
    "    return p_score, n_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на совпадения предсказаний и правильных ответов. Так получилось, что в 3 текстах вообще не встретились слова из собранных словарей, поэтому предсказать оценку невозможно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: positive\n",
      "answer: рекомендует \n",
      "\n",
      "predict: positive\n",
      "answer: не рекомендует \n",
      "\n",
      "predict: negative\n",
      "answer: не рекомендует \n",
      "\n",
      "predict: negative\n",
      "answer: не рекомендует \n",
      "\n",
      "predict: can not predict\n",
      "answer: не рекомендует \n",
      "\n",
      "predict: positive\n",
      "answer: рекомендует \n",
      "\n",
      "predict: can not predict\n",
      "answer: рекомендует \n",
      "\n",
      "predict: positive\n",
      "answer: рекомендует \n",
      "\n",
      "predict: positive\n",
      "answer: не рекомендует \n",
      "\n",
      "predict: positive\n",
      "answer: рекомендует \n",
      "\n",
      "predict: can not predict\n",
      "answer: не рекомендует \n",
      "\n",
      "predict: negative\n",
      "answer: не рекомендует \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in test_dict.keys():\n",
    "    p_score, n_score = predict_verdict(text, adj_pos, adj_neg)\n",
    "    if p_score > n_score:\n",
    "        print('predict: positive')\n",
    "    elif p_score == n_score:\n",
    "        print('predict: can not predict')\n",
    "    else:\n",
    "        print('predict: negative')\n",
    "    print('answer:', test_dict[text], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем accuracy. Получилось 75%. Но это не совсем правда, потому что у нас был \"третий класс\" отзывов, оценку которых не получилось определить. Такие отзывы определялись в отрицательные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "# 1 - pos, 0 - neg\n",
    "predict = []\n",
    "gold = []\n",
    "for text in test_dict.keys():\n",
    "    p_score, n_score = predict_verdict(text, adj_pos, adj_neg)\n",
    "    if p_score > n_score:\n",
    "        predict.append(1)\n",
    "    else:\n",
    "        predict.append(0)\n",
    "    if test_dict[text] == 'рекомендует':\n",
    "        gold.append(1)\n",
    "    else:\n",
    "        gold.append(0)\n",
    "\n",
    "print(\"Accuracy: %.4f\" % accuracy_score(predict, gold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Улучшить показатели можно было бы с помощью увеличения выборки. Я взяла минимум (30 слов на каждый тип), потому что без долгих sleep'ов приходилось бы мучаться с капчами, а с ними работает довольно долго. С большей выборкой было бы большее разнообразие фильмов и оценочные слова в итоге оказались бы в топе по частотности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще было бы полезно сбаланировать выборку. В моей программе был установлен только нижний порог по длине, но можно было бы ограничить ее и сверху. В целом, было бы неплохо уравнять тексты как можно лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
